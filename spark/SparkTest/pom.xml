<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>cn.hoob.spark</groupId>
	<artifactId>SparkTest</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
		<encoding>UTF-8</encoding>
		<scala.version>2.11.8</scala.version>
		<scala.binary.version>2.11</scala.binary.version>
		<spark.version>2.4.3</spark.version>
		<hadoop.version>2.8.1</hadoop.version>
	</properties>
	<dependencies>
		<!-- 导入scala的依赖 -->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>

		<!-- 指定hadoop-client API的版本 -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-client</artifactId>
			<version>${hadoop.version}</version>
		</dependency>

		<!-- 导入spark的依赖 -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- 导入spark sql的依赖 -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- 导入spark mllib的依赖 机器学习-->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- spark如果想整合Hive，必须加入hive的支持 -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- spark steaming的依赖 -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- sparkSteaming跟Kafka整合的依赖 -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka-0-10_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<!--StructuredStreaming跟Kafka整合的依赖 -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql-kafka-0-10_2.11</artifactId>
			<version>${spark.version}</version>
		</dependency>
        <!-- spark-streaming-flume  -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-flume_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!-- spark-streaming-flume-sink -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-flume-sink_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<!--  flume avro -->
		<dependency>
			<groupId>org.apache.avro</groupId>
			<artifactId>avro</artifactId>
			<version>1.8.2</version>
		</dependency>

		<!--  flume avro-ipc -->
		<dependency>
			<groupId>org.apache.avro</groupId>
			<artifactId>avro-ipc</artifactId>
			<version>1.8.2</version>
		</dependency>

		<!--spark-csv  读取csv-->
		<dependency>
			<groupId>com.databricks</groupId>
			<artifactId>spark-csv_${scala.binary.version}</artifactId>
			<version>1.4.0</version>
		</dependency>

		<!--spark-excel  读取excel-->
		<dependency>
			<groupId>com.crealytics</groupId>
			<artifactId>spark-excel_${scala.binary.version}</artifactId>
			<version>0.13.1</version>
		</dependency>

		<!--spark-xml  读取xml-->
		<dependency>
			<groupId>com.databricks</groupId>
			<artifactId>spark-xml_${scala.binary.version}</artifactId>
			<version>0.6.0</version>
		</dependency>

        <dependency>
            <groupId>ch.qos.logback</groupId>
            <artifactId>logback-core</artifactId>
            <version>1.2.3</version>
        </dependency>
		<dependency>
			<groupId>ch.qos.logback</groupId>
			<artifactId>logback-core</artifactId>
			<version>1.2.3</version>
		</dependency>
		<dependency>
			<groupId>commons-codec</groupId>
			<artifactId>commons-codec</artifactId>
			<version>1.12</version>
		</dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <version>1.18.8</version>
        </dependency>

        <dependency>
            <groupId>com.mchange</groupId>
            <artifactId>c3p0</artifactId>
            <version>0.9.5.2</version>
        </dependency>
		<dependency>
			<groupId>com.alibaba</groupId>
			<artifactId>fastjson</artifactId>
			<version>1.2.32</version>
		</dependency>

		<!--分词组件-->
		<dependency>
			<groupId>org.apdplat</groupId>
			<artifactId>word</artifactId>
			<version>1.2</version>
		</dependency>
		<dependency>
			<groupId>org.jsoup</groupId>
			<artifactId>jsoup</artifactId>
			<version>1.11.3</version>
		</dependency>

		<!-- mysql的连接驱动依赖 -->
		<dependency>
			<groupId>mysql</groupId>
			<artifactId>mysql-connector-java</artifactId>
			<version>8.0.28</version>
		</dependency>

		<!-- redis -->
		<dependency>
			<groupId>redis.clients</groupId>
			<artifactId>jedis</artifactId>
			<version>2.9.0</version>
		</dependency>



	</dependencies>

	<build>
		<finalName>SprakTest</finalName>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-assembly-plugin</artifactId>
				<version>2.4.1</version>
				<configuration>
					<appendAssemblyId>false</appendAssemblyId>
					<finalName>cleandata</finalName>
					<descriptorRefs>
						<!-- 将依赖的jar包中的class文件打进生成的jar包 -->
						<descriptorRef>jar-with-dependencies</descriptorRef>
					</descriptorRefs>
					<archive>
						<manifest>
							<addClasspath>true</addClasspath>
							<!-- 有Main函数的类 -->
							<mainClass>com.hadoop.CleanData</mainClass>
						</manifest>
					</archive>
				</configuration>
				<executions>
					<execution>
						<id>make-assembly</id>
						<phase>package</phase>
						<goals>
							<!-- <goal>single</goal> -->
							<goal>assembly</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>
</project>